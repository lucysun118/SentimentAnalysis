---
title: "S&DS 230 Final Project"
author: Sophia Moore, Vivian Weng, and Lucy Sun
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

For our final project, we have decided to examine a data set regarding the food preferences and lifestyle choices of college students. The data set that we have selected includes 126 responses from university-level students; these responses provide information on current and past food preferences, grades, nutrition, exercise levels, among other categories. We chose this data set because its content felt relevant to us as college students. 

The source of our data can be found [here](https://www.kaggle.com/datasets/borapajo/food-choices). Additionally, the code book that describes our data set variables can be found at this [link](http://reuningscherer.net/s&ds230/data/codebook_food.pdf). 

We will begin by loading in the contents of our data into an object called 'data': 

```{r}
#load in the contents of our data into an object called 'data': 
data <- read.csv("food_coded.csv")

#display the variable names included in the 'data' object
names(data)

#display the first 6 rows of the 'data' object
head(data)

#attach the 'data' object
attach(data)
```

## Data

The variables from our data set that we will focus on in this report include:

1. Gender 
+ This is an integer indicating the gender of the respondents. 1 indicates female; 2 indicates male.
2. type_sports
+ This is an open ended character variable in which the respondent was asked what kind of sports they are involved in. We will clean this variable. 
3. GPA
+ This is a character variable consisting of a numeric representation of each student's GPA.
4. life_rewarding
+ This is an integer variable indicating on a scale of 1-10 how likely students agree with the statement "I feel life is very rewarding", with 1 representing "strongly agree" and 10 representing "strong disagree" on a scale. In other words, this variable appears to be a good measure of how rewarding students find their life at the point of which they are taking this survey.

**ADD MORE TO THIS SECTION AS WE CONTINUE**


## Data Cleaning 

We will begin by cleaning the 'type_sports' variable. An issue with the data contained within this variable is that many of the values referring to the same sport type are formatted differently (for example “Rec Volleyball” vs. “Volleyball"). We will clean the data so that anything referring to the same sports category represents only 1 unique value. 

```{r}
#Get the current number of unique values in type_sports:
length(unique(type_sports))

#Make everything lowercase and remove preceding or trailing spaces at the end of text:
type_sports <- trimws(tolower(type_sports))

#Condense all responses that indicate no sport is played into a singular unique value (including those specific, weirdly formatted phrases):
type_sports <- gsub(".*no.*", "none", type_sports)
weirdResponse <- c("i danced", "used to", "rarely though")
for (i in 1:length(weirdResponse)){
   type_sports <- gsub(paste0(".*", weirdResponse[i] ,".*"), "none", type_sports)
}

#Make an 'unspecified' category for those values not entered:
type_sports <- gsub("nan", "unspecifed", type_sports)

#Make a 'multisport' category for those respondents who indicated that they played more than one sport:
multisportPhrases <- c(",", "&", "and")
for (i in 1:length(multisportPhrases)){
   type_sports <- gsub(paste0(".*", multisportPhrases[i] ,".*"), "multisport", type_sports)
}

#Sort the sports into categories by seasons (fall, winter, and spring sports):
fallSports <- c("soccer", "football", "volleyball", "field hockey", "water polo", "rowing", "crew")
winterSports <- c("ice hockey", "wrestling", "dancing", "skiing", "basketball")
springSports <- c("tennis", "softball", "baseball", "lacrosse", "running", "car racing", "horse back")

for (i in 1:7){
   type_sports <- gsub(paste0(".*", fallSports[i] ,".*"), "fall", type_sports)
   type_sports <- gsub(paste0(".*", springSports[i] ,".*"), "spring", type_sports)
   if (i<= 5) {
     type_sports <- gsub(paste0(".*", winterSports[i] ,".*"), "winter", type_sports)
   }
}

#Fix two unusual responses, lack of specificity, and spelling errors by respondents:
type_sports <- gsub("fotball", "fall",  gsub("tennis soccer gym", "multisport",  gsub("hockey", "winter", type_sports)))

#Finally, get the current number and categories of unique values in type_sports after cleaning the data:
length(unique(type_sports))
unique(type_sports)

```

## Descriptive Plots 

With our cleaned 'type_sports' variable, we can now create a box plot that maps sports type against other variables. For example, we can create a boxplot of sports type by GPA:

```{r}
boxplot(as.numeric(GPA) ~ type_sports, xlab = "Type of Sport Played", ylab = "Student GPA", main = "Student GPA by Type of Sport Played", col = c("orange", "yellow", "lightgreen", "pink", "gold", "cadetblue1"))
```

*From this boxplot of student GPA by sport type, we can see that there does not appear to be very clear differences in median student GPA across the type of sport played. The median GPA appears to be around 3.5 for each of the sport types, but the median student GPA for the "unspecified" sport group appears to be visibly lower than the median of the other sport groups, at around 3.3. There are also some notable pieces of information we can extract from the boxplot; for example, the range of student GPAs among the group that plays spring sports appears to be greatest compared to the other sport groups; within the spring sport group, the minimum of the first quartile of student GPA is the lowest across the groups, and the maximum GPA value in the spring sport group (that is not an outlier) is also one of the highest across all groups. In addition, there does not appear to be many outliers in this boxplot, which is a good indication that the data is likely normally distributed.*

Let's compare the mean GPA for students who play a fall sport against students who play a winter sport. We will perform a t-test

```{r}
#Make a temporary data set that contains only information from students who were either fall or winter athletes:
temp <- data[type_sports == "fall" | type_sports == "winter", ]

#Update our temporary data set to contain only rows where GPA is not missing
temp <- data[!is.na(as.numeric(GPA)),]

#Perform a t-test and get the resulting confidence interval for the mean difference:
(meanComp <- t.test(as.numeric(temp$GPA[type_sports == "fall"]) , as.numeric(temp$GPA[type_sports == "winter"])))
ci_tTest <- meanComp$conf.int
```

We see that the 95% confidence interval for difference in mean is between approximately -.2 and .28. Our high p-value indicates that we cannot reject the null hypothesis in favor of the alternative. There is not sufficient evidence to suggest that the true difference means is not equal to 0. We can also create a bootstrap confidence interval for the difference in mean GPA between fall athletes and winter athletes:

```{r}
#Create bootstrap confidence interval using samples: 
n_samp <- 10000  #The number of samples we will take 
meanDif <- rep(NA, n_samp) # A vector for our bootstrapped means

for (i in 1:n_samp) {
   avgFall <- mean(sample(na.omit(as.numeric(temp$GPA[type_sports == "fall"])), length(temp$type_sports[type_sports == "fall"]), replace = T))
   avgWinter <- mean(sample(na.omit(as.numeric(temp$GPA[type_sports == "winter"])), length(temp$type_sports[type_sports == "winter"]), replace = T))
   meanDif[i] <- avgFall - avgWinter
}
ci_meanDif <-  quantile(meanDif, c(0.025, 0.975))
ci_tTest <- meanComp$conf.int
ci_meanDif

#To make a histogram with lines for 95% parametric and bootstrap confidence intervals:
hist(meanDif, col = "mediumpurple1", main = "Average Difference in Mean GPA Between
Fall and Winter Athletes", breaks = 30, cex.main = .8, xlab = "Mean Difference
")
abline(v = ci_meanDif, lwd = 3, col = "red")
abline(v = ci_tTest, lwd = 3, col = "green", lty = 2)
legend("topright", c("Original CI","Boot CI"), lwd = 3, col = c("green","red"), lty =
c(2,1))
```
*We see graphically, from the histogram with the theoretical and bootstrapped CI bands, that the two confidence intervals are very similar. We see that t-test confidence interval is only slightly larger than the bootstrap confidence interval: its lower parameter is slightly lower (about -0.18 for the original CI and about -0.17 for the bootstrapped CI lower bounds) and its higher parameter (about 0.3 for both the theoretical and bootstrapped CI upper bounds) is slightly larger. This is a possible indication that there aren't too many outliers in the data that may be ...., and that using either the bootstrapped or theoretical CI values are fine. Further, based on the relatively symmetric distribution of the data in the histogram, it seems likely that our data is normally distributed, which is good.*

Next, we were curious to see whether there was a correlation between the student GPA and their numeric answer to the question of whether they find life rewarding, as indicated on a 1-10 scale by the life_rewarding variable in the dataset, where 1 representing sentiments that the participant strongly agrees with the statement "I feel life is very rewarding" and 10 representing sentiments that the participant disagrees with the statement.

Data Cleaning of GPA and life_rewarding variables
``` {r}
library(dplyr)
#First, we converted the GPA and life_rewarding answers to numeric, stored in a temporary dataset, labeled 'temp2'
temp2 <- data[,c('GPA', 'life_rewarding')]

#check the types of variables of GPA and life_rewarding
str(temp2$GPA) 
str(temp2$life_rewarding)

#GPA is currently stored as character values, and we also notice some extraneous info in the answers, so we definitely need to do some data cleaning and convert the cleaned char values into numeric. The life_rewarding variable values are already numeric integers, so no need to do more work on this variable.

#Remove preceding or trailing spaces at the end of text:
temp2$GPA <- trimws(temp2$GPA)

#Condense all responses that indicate no sport is played into a singular unique value (including those specific, weirdly formatted phrases):
temp2$GPA <- gsub(" .*", "", temp2$GPA)


weirdResponse <- c("Personal", "nan", "Unknown")
for (i in 1:length(weirdResponse)){
   temp2$GPA <- gsub(paste0(".*", weirdResponse[i],".*"), NA, temp2$GPA)
}

temp2$GPA

#Everything looks good now in the GPA variable, so let's convert the variable values, currently character types, into numeric values and round to 1 decimal place
temp2$GPA <- round(as.numeric(temp2$GPA), 1)

#Data Cleaning for the life_rewarding variable - change the one "NaN" value into 'NA' as convert everything into numeric
temp2$life_rewarding <- as.numeric(gsub("NaN", NA, temp2$life_rewarding))

#If we look at the length of both variables, we see that both have 125 values, but there are unfortunately some individuals that did not answer across both variables (4 in GPA and 1 in life_rewarding). So, let's remove those individuals from both datasets
length(temp2$GPA)
length(temp2$life_rewarding)
temp2 <- temp2[!is.na(temp2$GPA),]
temp2 <- temp2[!is.na(temp2$life_rewarding),]

#check both variables again after cleaning and removing NA responses
length(temp2$GPA)
length(temp2$life_rewarding)
temp2

#now both variables have the corresponding individuals that answered NA to either or both questions removed, and both columns are of the same length, which is good! Now we can proceed.
```

Scatterplots: Next, we wanted to look at the correlation (if it exists) between the variables "GPA" and "life_rewarding". We started by making a scatterplot to see the visual representation of the numeric variables.
```{r}
plot(temp2$life_rewarding ~ temp2$GPA, main = "Scatterplot of Students' View of Life (How Rewarding on a scale of 1-10) vs GPA", xlab = 'GPA', ylab = 'Student Perception of How Rewarding their Life is (1-10)', cex.main = 0.9, pch = 19, col = "pink")

#let's try jittering the plot.
plot(jitter(temp2$life_rewarding) ~ jitter(temp2$GPA), main = "Scatterplot of Students' View of Life (How Rewarding on a scale of 1-10) vs GPA", xlab = 'GPA', ylab = 'Student Perception of How Rewarding their Life is (1-10)', cex.main = 0.9, pch = 19, col = "pink")

#By jittering the data, it becomes harder to see the data so let's try proportional radii instead
freq <- c(table(temp2$life_rewarding, temp2$GPA))
freq

y1 <- rep(c(1:10), 10)
x1 <- sort(rep(seq(2.1,4,0.1), 5))
length(seq(2.1,4,0.1))
length(x1)

plot(x1, y1, pch = 19, col = "blue", xlab = "GPA", ylab = "Rewarding Life Ranking", cex.main = 0.9, cex = sqrt(freq))

#pastes correlation values (excluding NA values)
mtext(paste("Sample Correlation =", round(cor(temp2$life_rewarding, temp2$GPA, use = "complete.obs"), 3)), cex = 1.2, line = 0)
mtext("How Rewarding Participant Finds Life vs Their GPA", cex = 1.2, line = 1)
```



Next, let's group individuals into 4 groups defined by GPA values to observe whether differences in median life-rewardingness ranking across the GPA groups are significant.

``` {r}
#First, let's split the participant GPA values into 4 groups: 2.0-2.5, 2.6-3.0, 3.1-3.5, 3.6-4.0
for (i in 1:length(temp2$GPA)) {
   if (temp2$GPA[i] %in% c(2.0, 2.1, 2.2, 2.3, 2.4, 2.5)) {
      temp2$GPA[i] = '2.0-2.5'
   }
   else if (temp2$GPA[i] %in% c(2.6, 2.7, 2.8, 2.9, 3.0)) {
      temp2$GPA[i] = '2.6-3.0'
   }
   else if (temp2$GPA[i] %in% c(3.1, 3.2, 3.3, 3.4, 3.5)) {
      temp2$GPA[i] = '3.1-3.5'
   }
   else if (temp2$GPA[i] %in% c(3.6, 3.7, 3.8, 3.9, 4.0)) {
      temp2$GPA[i] = '3.6-4.0'
   }
}

temp2$GPA

#Now, make a boxplot of the results
boxplot(temp2$life_rewarding ~ temp2$GPA, col = c("purple", "pink", "yellow", "orange"))

```
*Interestingly, the boxplot of answers of whether life is rewarding by gender shows different median values across the four GPA groups. The lowest median GPA is in the 3.1-3.5 GPA group, with a life-rewardingness ranking of about 3, and the highest ranking is in the 2.6-3.0 group, with a life-rewardingness ranking of about 7. There does not yet seem to be a clear correlation between life_rewardingness and GPA value.*

Permutation Test: Now, let's see if there is a significant difference in the median ranking of life rewarding-ness between students in the 3.0-3.5 and 3.6-4.0 catefories by conducting a permutation test. We are interested primarily in comparing the two GPA groups '3.1-3.5' and '3.6-4.0'.

``` {r}
set.seed(230)

actualdiff <- median(temp2$life_rewarding[temp2$GPA == "3.6-4.0"]) - median(temp2$life_rewarding[temp2$GPA == "3.1-3.5"])


#replace is false in default for sample() fxn
fake <- sample(temp2$GPA)

N <- 10000
diffvals <- rep(NA, N)

#for loop to fill diffvals as difference of medians between both genders, for each sample
for (i in 1:N) {
  fake <- sample(temp2$GPA)
  diffvals[i] = median(sample(temp2$life_rewarding[fake == "3.6-4.0"])) - median(sample(temp2$life_rewarding[fake == "3.1-3.5"]))
}

pval <- mean(abs(diffvals) >= abs(actualdiff))
pval

hist(diffvals, main = "Histogram of Permuted Sample Differences in Life Rewarding-ness Ranking between GPA Groups", cex.main = 0.85, xlab = "Life Rewardingness Rankings (Differences)", col = "pink")

abline(v = actualdiff, col = "blue", lwd = 3)
text(actualdiff - 0.15, 700 , paste("Actual Diff in Means =", round(actualdiff, 2)), srt = 90)
```
*The p-value, 0.3251 (obtained from the permutation test done on the difference of medians between the "fake" values between the '3.1-3.5' and '3.6-4.0' GPA group life-rewardingness rankings), is greater than the significance level of 0.05. Therefore, we have failed to reject the null hypothesis, that there is no significant difference between the median life-rewardingness ranking values across the 2 GPA groups. There is not sufficient evidence to prove that the difference between 3.1-3.5 and 3.6-4.0 GPA group median life-rewardingness values is nonzero. The alternative hypothesis is that there is a nonzero difference between the median life-rewardingness ranking for the '3.1-3.5' GPA group and the median life-rewardingness ranking for the '3.6-4.0' group. Because the p-value is greater than the alpha value of 0.05, there is not sufficient evidence to prove that the difference between '3.1-3.5' and '3.6-4.0' median life-rewardingness values is nonzero (but not enough evidence to prove the alternative hypothesis with certainty).*

Repeat the above with another pair of GPA groups: the 2.6-3.0 and 3.1-3.5 GPA groups. These two groups were chosen for the second permutation test because the lowest median GPA is in the 3.1-3.5 GPA group and the highest ranking is in the 2.6-3.0 group. Therefore, we were interested in determining whether the large difference in ranking is statistically significant.

``` {r}
actualdiff <- median(temp2$life_rewarding[temp2$GPA == "2.6-3.0"]) - median(temp2$life_rewarding[temp2$GPA == "3.1-3.5"])


#replace is false in default for sample() fxn
fake <- sample(temp2$GPA)

N <- 10000
diffvals <- rep(NA, N)

#for loop to fill diffvals as difference of medians between both genders, for each sample
for (i in 1:N) {
  fake <- sample(temp2$GPA)
  diffvals[i] = median(sample(temp2$life_rewarding[fake == "2.6-3.0"])) - median(sample(temp2$life_rewarding[fake == "3.1-3.5"]))
}

pval <- mean(abs(diffvals) >= abs(actualdiff))
pval

hist(diffvals, main = "Histogram of Permuted Sample Differences in Life Rewarding-ness between '2.6-3.0' and '3.1-3.5' GPA Groups", cex.main = 0.85, xlab = "Life Rewardingness Rankings (Differences)", col = "yellow")

abline(v = actualdiff, col = "blue", lwd = 3)
text(actualdiff - 0.15, 700 , paste("Actual Diff in Means =", round(actualdiff, 2)), srt = 90)
```
*The p-value, 0.06, obtained from the permutation test is also greater than the significance level of 0.05. Therefore, we have failed to reject the null hypothesis, that there is no significant difference between the median life-rewardingness ranking values across the 2 GPA groups: '2.6-3.0' and '3.1-3.5'.  The alternative hypothesis is that there is a nonzero difference between the median life-rewardingness ranking for the '3.1-3.5' GPA group and the median life-rewardingness ranking for the '2.6-3.0' group. Because the p-value is greater than the alpha value of 0.05, there is not sufficient evidence to prove that the difference between the 2 groups' median life-rewardingness values is nonzero (but not enough evidence to prove the alternative hypothesis with certainty). Ultimately, considering both permutation tests, there is not sufficient evidence to prove that the difference between '2.6-3.0' and '3.1-3.5' GPA group median life-rewardingness values is nonzero, but we do notice that the p-value for the second permutation test is lower than the p-value for the first permutation test. This indicates ....* 

**DONE by Sophia**
- data cleaning
- boxplot
- histogram
- t-test
- bootstrap CI

**DONE by Lucy**
- more data cleaning (GPA and life_rewarding)
- some explanations for Sophia's part (graphs etc)
- scatterplot (between GPA and life_rewarding)
- permutation test

**TO DO:**
- normal quantile plot
- residual plots
- multiple regression
- one of ANOVA, ANCOVA, Logistic Regression, Multinomial Regression, OR data scraping off a website 



